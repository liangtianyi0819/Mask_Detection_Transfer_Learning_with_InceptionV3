{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jB-kW9JnHYdK"
   },
   "source": [
    "# Mask Detection using Transfer Learning based on InceptionV3 Neural Network\n",
    "Author: [Tianyi Liang](https://www.linkedin.com/in/tianyi-liang-at-bu/)\n",
    "\n",
    "## Introduction\n",
    "This project aims to detect whether a person is wearing a mask or not using a Convolutional Neural Network (CNN) model. The model is built using transfer learning based on the InceptionV3 architecture. The dataset used for this project is publicly available on Kaggle.\n",
    "\n",
    "This project is divided into several sections:\n",
    "\n",
    "1. [Import Necessary Packages](#import-packages)\n",
    "2. [Download the Dataset](#download-dataset)\n",
    "3. [Read the Data into Memory](#read-data)\n",
    "4. [Perform Data Visualization](#data-visualization)\n",
    "5. [Normalize the Data and Format it into the Required Shape](#normalize-data)\n",
    "6. [Check the Balance of the Data](#check-balance)\n",
    "7. [Implement Image Augmentation to Prevent Overfitting](#image-augmentation)\n",
    "8. [Build the Network using InceptionV3 and a Custom Classifier and Train](#build-network)\n",
    "9. [Visualize Training Accuracy and Loss](#visualize-training)\n",
    "10. [Evaluate the Model and Analyze Wrong Cases](#evaluate-model)\n",
    "11. [Conclusion and Insights](#conclusion)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"import-packages\"></a>\n",
    "## Import Necessary Packages\n",
    "In this stage, we import all the necessary packages required for the project. These include TensorFlow, Keras, OpenCV, opendatasets, Numpy, Pandas, Seaborn, and Matplotlib.\n",
    "\n",
    "### Requirements:\n",
    "- Python 3.7\n",
    "- TensorFlow\n",
    "- Keras\n",
    "- OpenCV\n",
    "- opendatasets\n",
    "- Numpy\n",
    "- Pandas\n",
    "- Seaborn\n",
    "- Matplotlib\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o8e0yTJktvxY",
    "outputId": "033dd8b0-cc08-4eb3-f6e0-de01b3cc7064",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "##Import necessary packages\n",
    "!pip install opendatasets\n",
    "!pip install opencv-python\n",
    "!pip install opencv-contrib-python\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import opendatasets as od\n",
    "\n",
    "from cv2 import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation, Input, Add, \\\n",
    "                   BatchNormalization, Flatten, Conv2D, \\\n",
    "                   AveragePooling2D, MaxPooling2D, ZeroPadding2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTh3lMfEH6vu"
   },
   "source": [
    "<a id=\"download-dataset\"></a>\n",
    "## Download the Dataset\n",
    "In this step, I retrieve the dataset required for our project. The dataset, titled \"Face Mask 12k Images Dataset\" by ASHISH JANGRA, is publicly available on Kaggle. It comprises images of individuals either wearing masks or not.\n",
    "\n",
    "I utilize the opendatasets Python package to download the dataset directly from Kaggle. This package simplifies the process of downloading datasets from online sources, making it a valuable tool for data science projects.\n",
    "\n",
    "The dataset is stored in the face-mask-12k-images-dataset/Face Mask Dataset/ directory after download.\n",
    "\n",
    "##### (Link to the dataset: [Face Mask 12k Images Dataset by ASHISH JANGRA](https://www.kaggle.com/datasets/ashishjangra27/face-mask-12k-images-dataset))\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BEQhzQLtvtQ",
    "outputId": "131fd8d4-e600-4ef8-c8c3-d2d7bf06dc33"
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "od.download(\"https://www.kaggle.com/datasets/ashishjangra27/face-mask-12k-images-dataset\")\n",
    "\n",
    "# Define the root path for the dataset\n",
    "root_path = \"face-mask-12k-images-dataset/Face Mask Dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXd3wTngII3l"
   },
   "source": [
    "<a id=\"read-data\"></a>\n",
    "## Read the Data into Memory\n",
    "In this step, I load the images and their corresponding labels (mask or no mask) into memory. This is an essential step as it allows me to manipulate and analyze the data using Python.\n",
    "\n",
    "I create a dictionary named dataset to store the image paths, classifications (mask or no mask), set types (train, test, or validation), and image pixel values. I then convert this dictionary into a Pandas DataFrame for easier data manipulation.\n",
    "\n",
    "The images are loaded using the OpenCV library, resized to a uniform size of 224x224 pixels, and their color channels are reversed from BGR to RGB.\n",
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fd4cN8t5vTgW",
    "outputId": "6ace4040-d47f-4bff-fc7b-e1b92f335d01"
   },
   "outputs": [],
   "source": [
    "# Initialize the dataset dictionary\n",
    "dataset = {\"path\": [], \"classification\": [], \"set\": [], \"value\": []}\n",
    "\n",
    "# Loop over the train/test folders\n",
    "for train_test in os.listdir(root_path):\n",
    "\n",
    "    # Loop over the Mask/WithoutMask folders\n",
    "    for true_false in os.listdir(root_path+\"/\"+train_test):\n",
    "\n",
    "        # Loop over each image inside\n",
    "        for image in glob.glob(root_path + \n",
    "                     train_test + \"/\" + \n",
    "                     true_false + \"/\" + \n",
    "                     \"*.png\"):\n",
    "\n",
    "            # Read the image\n",
    "            img = cv2.imread(image, 3)\n",
    "            img = np.asarray(cv2.resize(img, \n",
    "                    dsize=(224, 224)))\n",
    "\n",
    "            # Reverse the color channels\n",
    "            img = cv2.merge(cv2.split(img)[::-1])\n",
    "\n",
    "            # Append the data to the dataset dictionary\n",
    "            dataset[\"path\"].append(image)\n",
    "            dataset[\"classification\"].append(np.uint8(1) if true_false == \"WithMask\" else np.uint8(0))\n",
    "            dataset[\"set\"].append(train_test.lower())\n",
    "            dataset[\"value\"].append(img)\n",
    "\n",
    "# Convert the dataset dictionary to a Pandas DataFrame\n",
    "df_dataset = pd.DataFrame(dataset)\n",
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_XICQkmISpz"
   },
   "source": [
    "<a id=\"data-visualization\"></a>\n",
    "## Perform Data Visualization\n",
    "Visualizing the data is a crucial step in any data analysis task. It helps me understand the data better and can provide insights that are not immediately apparent from the raw data.\n",
    "\n",
    "In this section, I plot some sample images from the dataset along with their corresponding labels. This gives me a visual understanding of what the images look like and what the model will be learning from.\n",
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "id": "E8AKiAzowMSR",
    "outputId": "3e2bf262-5002-4289-9e9b-07163b133ae4"
   },
   "outputs": [],
   "source": [
    "def set_seed():\n",
    "    InitSeed = 23\n",
    "    tf.random.set_seed(InitSeed)\n",
    "    np.random.seed(InitSeed)\n",
    "\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize = (20, 15))\n",
    "\n",
    "# Generate a random sample of 25 images\n",
    "np.random.seed(1)\n",
    "sample = np.random.choice(range(len(df_dataset)), size=25, replace=False)\n",
    "\n",
    "# Plot the sample images\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    img = df_dataset.loc[sample[i],\"value\"]\n",
    "    plt.imshow(img)\n",
    "\n",
    "    # Get the classification label\n",
    "    classification = 'WithMask' if df_dataset.loc[sample[i],\"classification\"] == 1 else \"WithoutMask\"\n",
    "\n",
    "    # Display the classification label as the title\n",
    "    plt.title(classification, size = 15)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWrdB79eIjdK"
   },
   "source": [
    "<a id=\"normalize-data\"></a>\n",
    "## Normalize the Data and Format it into the Required Shape <a name=\"normalize-data\"></a>\n",
    "Before feeding the data into the model, it's important to normalize it and format it into the required shape. Normalization is a standard pre-processing step that ensures that each input parameter (pixel, in this case) has a similar data distribution. This makes convergence faster while training the model.\n",
    "\n",
    "In this section, I normalize the pixel values of the images to be between 0 and 1. Also, I format the data into the shape required by the InceptionV3 model.\n",
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsPapFBq0NLV",
    "outputId": "37451fe2-0054-4fe2-c655-3b40c3bb0da3"
   },
   "outputs": [],
   "source": [
    "# Create dataframes for each set\n",
    "train_set = pd.DataFrame(df_dataset[df_dataset[\"set\"] == \"train\"]).loc[:, [\"value\", \"classification\"]]\n",
    "test_set = pd.DataFrame(df_dataset[df_dataset[\"set\"] == \"test\"]).loc[:, [\"value\", \"classification\"]]\n",
    "valid_set = pd.DataFrame(df_dataset[df_dataset[\"set\"] == \"validation\"]).loc[:, [\"value\", \"classification\"]]\n",
    "\n",
    "# Normalize the images and convert them to numpy arrays\n",
    "x_train = np.asarray(train_set[\"value\"].tolist()) / 255\n",
    "y_train = np.asarray(train_set[\"classification\"].tolist())\n",
    "x_test = np.asarray(test_set[\"value\"].tolist()) / 255\n",
    "y_test = np.asarray(test_set[\"classification\"].tolist())\n",
    "x_valid = np.asarray(valid_set[\"value\"].tolist()) / 255\n",
    "y_valid = np.asarray(valid_set[\"classification\"].tolist())\n",
    "\n",
    "# Clean up memory\n",
    "del df_dataset, train_set, test_set, valid_set, img, dataset\n",
    "del glob, od, pd, cv2\n",
    "gc.collect()\n",
    "\n",
    "# Print the shape of the data arrays\n",
    "print(\"x_train dimension:\", x_train.shape, \"\\ny_train dimension:\", y_train.shape,\n",
    "   \"\\nx_test dimension:\", x_test.shape, \"\\ny_test dimension:\", y_test.shape,\n",
    "   \"\\nx_valid dimension:\", x_valid.shape, \"\\ny_valid dimension:\", y_valid.shape,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FW6xy_5wJYbJ"
   },
   "source": [
    "<a id=\"check-balance\"></a>\n",
    "## Check the Balance of the Data <a name=\"check-balance\"></a>\n",
    "I need to ensure that our dataset is balanced, i.e., there is an equal number of images for both classes (mask and no mask). An imbalanced dataset can lead to biased results, where the model might favor the class with more instances.\n",
    "\n",
    "### Data Balance Verification\n",
    "\n",
    "I calculate the number of instances for each class in the training, testing, and validation sets. The results are then visualized using a bar chart for a more intuitive understanding of the data distribution.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "-XyMKUCwDsop",
    "outputId": "a1253fae-9300-4fed-f9e9-12c71de54f91"
   },
   "outputs": [],
   "source": [
    "# Calculate the number of instances for each class in each set\n",
    "classes_distribution = {\"WithoutMask in Train\": np.sum(y_train == 0),\n",
    "              \"With in Train\": np.sum(y_train == 1),\n",
    "              \"WithoutMask in Test\": np.sum(y_test == 0),\n",
    "              \"With in Test\": np.sum(y_test == 1),\n",
    "              \"WithoutMask in Validation\": np.sum(y_valid == 0),\n",
    "              \"With in Validation\": np.sum(y_valid == 1)}\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize = (16, 9))\n",
    "color_A = (0.1, 0.4, 0.7)\n",
    "color_B = color_A[::-1]\n",
    "plt.bar(range(len(classes_distribution)), \n",
    "        list(classes_distribution.values()), \n",
    "        tick_label=list(classes_distribution.keys()),\n",
    "        color=[color_A, color_B])\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVs_k8YCJoZ2"
   },
   "source": [
    "<a id=\"image-augmentation\"></a>\n",
    "## Implement Image Augmentation to Prevent Overfitting\n",
    "To increase the diversity of the training data and prevent overfitting, I implement image augmentation techniques. These techniques include rotation, height shift, width shift, zoom, and horizontal flip.\n",
    "\n",
    "### Image Augmentation Setup\n",
    "\n",
    "I use the `ImageDataGenerator` function from Keras to create an image generator that can apply these augmentations to the training images. The parameters for the different augmentations are set as follows:\n",
    "\n",
    "- **Rotation**: Up to 30 degrees\n",
    "- **Height Shift**: Up to 10% of the image height\n",
    "- **Width Shift**: Up to 10% of the image width\n",
    "- **Zoom**: Up to 10%\n",
    "- **Horizontal Flip**: Enabled\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "sDZqB-RpkKQc",
    "outputId": "804f1a62-5559-49e4-bb90-819209782637"
   },
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "set_seed()\n",
    "\n",
    "# Initialize the image data generator with the desired transformations\n",
    "train_aug = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    height_shift_range=.1,\n",
    "    width_shift_range=.1,\n",
    "    zoom_range=.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "# Create an image generator for the training data\n",
    "augment = train_aug.flow(x_train[0:1], batch_size=1)\n",
    "\n",
    "# Display some augmented images to verify the setup\n",
    "plt.figure(figsize = (20, 15))\n",
    "for i in range(1, 26):\n",
    "    plt.subplot(1 + 5 % i, 5, i)\n",
    "    tf.random.set_seed(1)\n",
    "    augment.reset()\n",
    "    plt.imshow(augment.next().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Clean up memory\n",
    "del augment\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNx-l0f-J28i"
   },
   "source": [
    " <a id=\"build-network\"></a>\n",
    "## Build the Network using InceptionV3 and a Custom Classifier and Training the Model\n",
    "I build the network using the InceptionV3 model and a custom classifier. The model is based on the InceptionV3 architecture, a popular convolutional neural network (CNN) for image classification tasks.\n",
    "\n",
    "I build the network using the InceptionV3 model and a custom classifier. The model is based on the InceptionV3 architecture, a popular convolutional neural network (CNN) for image classification tasks.\n",
    "\n",
    "\n",
    "### Custom Classifier: `classifier_`\n",
    "\n",
    "This function defines a custom classifier that is added on top of the InceptionV3 base model. This classifier consists of several dense (fully connected) layers, each followed by batch normalization, activation, and dropout layers.\n",
    "\n",
    "- **Batch Normalization Layers**: These help to stabilize the learning process and reduce the generalization error.\n",
    "- **Dropout Layers**: These help to prevent overfitting by randomly setting a fraction of the input units to 0 at each update during training time.\n",
    "\n",
    "\n",
    "### Model Construction: `model_flow`\n",
    "\n",
    "This function constructs the overall model by first applying the InceptionV3 base model to the input, and then applying the custom classifier to the output of the base model.\n",
    "\n",
    "\n",
    "### Model Compilation: `input_output_compile`\n",
    "\n",
    "This function creates the final model by specifying the input and output, and compiles the model with the Stochastic Gradient Descent (SGD) optimizer, the sparse categorical cross-entropy loss function, and accuracy as the evaluation metric.\n",
    "\n",
    "\n",
    "### Learning Rate Scheduler: `lr_decay`\n",
    "\n",
    "This function defines a learning rate scheduler that decreases the learning rate as the training progresses, which can help to improve the convergence of the model.\n",
    "\n",
    "\n",
    "### Model Training: `fit_generator`\n",
    "\n",
    "The model is trained on the training data using the `fit_generator` method, with data augmentation applied to the training images to increase the diversity of the training data and help prevent overfitting. The learning rate scheduler is passed to the `fit_generator` method as a callback, so that the learning rate is updated at the end of each epoch.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gayA6Sqxrm0S"
   },
   "outputs": [],
   "source": [
    "# Define the custom classifier\n",
    "def classifier_(input_):\n",
    "\n",
    "    # Initialize the weights with Glorot normal initializer\n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed=767)\n",
    "    output_ = keras.layers.GlobalAveragePooling2D()(input_)\n",
    "    output_ = keras.layers.Flatten()(output_)\n",
    "    output_ = keras.layers.BatchNormalization()(output_)\n",
    "    output_prime = output_\n",
    "\n",
    "    output_ = keras.layers.Dense(2048, kernel_initializer=initializer)(output_)\n",
    "    output_ = keras.layers.BatchNormalization()(output_)\n",
    "    output_ = keras.layers.Activation('relu')(output_)\n",
    "    output_ = keras.layers.Dropout(0.55)(output_)\n",
    "\n",
    "    output_ = keras.layers.Dense(2048, kernel_initializer=initializer)(output_)\n",
    "    output_ = keras.layers.BatchNormalization()(output_)\n",
    "    output_ = keras.layers.Activation('relu')(output_)\n",
    "    output_ = keras.layers.Dropout(0.55)(output_)\n",
    "\n",
    "    output_ = keras.layers.Dense(1024, kernel_initializer=initializer)(output_)\n",
    "    output_ = keras.layers.BatchNormalization()(output_)\n",
    "    output_ = keras.layers.Activation('relu')(output_)\n",
    "    output_ = keras.layers.Dropout(0.55)(output_)\n",
    "\n",
    "    # Add the skip connection\n",
    "    output_ = keras.layers.Concatenate()([output_, output_prime])\n",
    "    output_ = keras.layers.Dense(512, activation='relu', kernel_initializer=initializer)(output_)\n",
    "\n",
    "    # Add the final output layer (binary classification)\n",
    "    output_ = keras.layers.Dense(2, activation='softmax')((output_))\n",
    "    return output_\n",
    "\n",
    "\n",
    "# Define the model\n",
    "def model_flow(input_):\n",
    "\n",
    "    # Load the InceptionV3 model\n",
    "    output_ = tf.keras.applications.InceptionV3(input_shape=(224, 224, 3),\n",
    "                               include_top=False,\n",
    "                               weights=None)(input_)\n",
    "\n",
    "    # Add the custom classifier on top\n",
    "    output_ = classifier_(output_)\n",
    "    return output_\n",
    "\n",
    "# Model compilation\n",
    "def input_output_compile():\n",
    "\n",
    "    # Shape of the training set\n",
    "    input_ = keras.layers.Input(shape=(224, 224, 3))\n",
    "    output_ = model_flow(input_)\n",
    "    clf = keras.Model(inputs=input_, outputs=output_)\n",
    "\n",
    "    # Compile the model with Stoachastic Gradient Descent optimizer\n",
    "    clf.compile(optimizer='SGD', loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return clf\n",
    "\n",
    "\n",
    "# Define learning rate scheduler\n",
    "def lr_decay(epoch, lr):\n",
    "\n",
    "    # Learning rate will be decayed by 0.95 each epoch\n",
    "    if epoch == 0:\n",
    "        return lr * 1 / (1 + 0.05 * epoch)\n",
    "\n",
    "    # Print the learning rate every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "        print('Test set accuracy: ' +\n",
    "              str(np.round(model.evaluate(x_test, y_test)[1] * 100, 2)) + '%')\n",
    "    return lr * 1 / (1 + 0.05 * epoch)\n",
    "\n",
    "\n",
    "# Visualize the neural network structure\n",
    "model = input_output_compile()\n",
    "tf.keras.utils.plot_model(model, show_shapes=True,\n",
    "              show_dtype=False,\n",
    "              show_layer_names=False,\n",
    "              show_layer_activations=True)\n",
    "\n",
    "\n",
    "# Train the model on the augmented data\n",
    "set_seed()\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_decay)\n",
    "hist = model.fit_generator(train_aug.flow(x_train, y_train, batch_size=24),\n",
    "                    epochs=8,\n",
    "                    validation_data=(x_valid, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ctvovc-MWlZ"
   },
   "source": [
    "<a id=\"visualize-training \"></a>\n",
    "## Visualizing Training Accuracy and Loss\n",
    "\n",
    "To understand how well the model is learning, I plot the accuracy and loss values for both the training and validation data over each epoch. This visualization helps to identify whether the model might be overfitting or underfitting and how quickly it is learning.\n",
    "\n",
    "The Python `matplotlib` library is used to create these plots:\n",
    "\n",
    "1. **Training and Validation Accuracy**: This plot shows how the accuracy of the model on the training and validation data changes over time.\n",
    "\n",
    "2. **Training and Validation Loss**: This plot shows how the loss of the model on the training and validation data changes over time.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kpGImxT4s5AY",
    "outputId": "6fd04bdf-6c12-441a-9581-d237cbbd59c6"
   },
   "outputs": [],
   "source": [
    "# Extract accuracy and loss from the model's history\n",
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "# Create a range of epochs\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize = (16, 8))\n",
    "plt.plot(epochs, acc, label='Training acc')\n",
    "plt.plot(epochs, val_acc, label='Validation acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize = (13, 8))\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8pl90zqMlB9"
   },
   "source": [
    "<a id=\"evaluate-model\"></a>\n",
    "# Evaluate the Model and Analyze Incorrect Predictions\n",
    "\n",
    "In this final section, I evaluate the performance of the model on the test dataset and analyze the instances where the model made incorrect predictions.\n",
    "\n",
    "The model's performance is evaluated using the `model.evaluate` method, which returns the loss value and metrics values for the model in test mode.\n",
    "\n",
    "Next, I generate predictions for the test dataset using the `model.predict` method. These predictions are then compared with the actual labels to identify the instances where the model made incorrect predictions.\n",
    "\n",
    "The incorrectly predicted images are visualized to provide insights into the types of images that the model struggles with.\n",
    "\n",
    "Finally, I calculate the True Positive (TP), False Positive (FP), True Negative (TN), and False Negative (FN) rates. These metrics provide a more detailed understanding of the model's performance.\n",
    "\n",
    "Specifically, the Precision, Recall, and Specificity metrics are calculated, which are crucial for evaluating the performance of a binary classification model.\n",
    "\n",
    "- Precision is important when the cost of False Positives is high.\n",
    "- Recall is important when the cost of False Negatives is high.\n",
    "- Specificity, also known as the True Negative Rate, measures the proportion of actual negatives that are correctly identified.\n",
    "\n",
    "By analyzing these metrics, I can gain a deeper understanding of the model's performance and identify potential areas for improvement.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pZ1HvP_-Xz_",
    "outputId": "118be517-5f82-4c89-a03f-8dc252944055"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate predictions for the test data\n",
    "y_pred = model.predict(x_test)\n",
    "correct_ = np.equal(np.argmax(y_pred, 1), y_test)\n",
    "x_wrong = x_test[np.logical_not(correct_)]\n",
    "\n",
    "# Visualize the instances where the model failed\n",
    "plt.figure(figsize = (20, 15))\n",
    "for i in range(1, len(x_wrong)-1):\n",
    "    plt.subplot(1 + 5 % i, 5, i)\n",
    "    plt.imshow(x_wrong[i].squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWcAaYBmQQ_r",
    "outputId": "9745bbc5-d4a2-4f79-e40e-bbedb7976596"
   },
   "outputs": [],
   "source": [
    "# Calculate TP, FP, TN, FN\n",
    "y_pred = np.argmax(y_pred, 1)\n",
    "TP = np.sum(np.logical_and(y_pred == 0, y_test == 0))\n",
    "FP = np.sum(np.logical_and(y_pred == 0, y_test == 1))\n",
    "TN = np.sum(np.logical_and(y_pred == 1, y_test == 1))\n",
    "FN = np.sum(np.logical_and(y_pred == 1, y_test == 0))\n",
    "print('TP:', TP, '\\nFP:', FP, '\\nTN:', TN, '\\nFN:', FN)\n",
    "print(\"\\nFP: predict as WithoutMask but actually WithMask\",\n",
    "   \"\\nFN: predict as WithMask but actually WithoutMask\")\n",
    "\n",
    "# IMPORTANT when false ALARM is unacceptable\n",
    "precision = str(np.round((TP/(TP+FP))*100, 2)) + \"%\"\n",
    "\n",
    "# IMPORTANT when missing ALARM is unacceptable, \n",
    "# rather have some fake ALARM\n",
    "recall = str(np.round((TP/(TP+FN))*100, 2)) + \"%\"\n",
    "\n",
    "# IMPORTANT when false ALARM is unacceptable\n",
    "specificity = str(np.round((TN/(TN+FP))*100, 2)) + \"%\"\n",
    "\n",
    "print(\"\\nPrecision:\", precision,\"\\nRecall:\", recall,\n",
    "    \"\\nSpecificity:\", specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "# Conclusion and Insights\n",
    "\n",
    "In this project, I developed a Convolutional Neural Network (CNN) model for mask detection using transfer learning based on the InceptionV3 architecture. The model was trained and evaluated on a dataset of images of people with and without masks.\n",
    "\n",
    "The model demonstrated promising results, with a good balance between precision and recall. However, it's important to note that in the context of mask detection, missing an alarm (failing to detect a person not wearing a mask) is a more serious issue than a false alarm (incorrectly identifying a person as not wearing a mask when they are). Therefore, future improvements to the model should focus on minimizing the number of missed alarms.\n",
    "\n",
    "Upon examining the instances where the model made incorrect predictions, I noticed that the model tends to struggle with images that contain anime icons or have very low resolution. This insight could guide future data collection and preprocessing efforts. For instance, we could aim to collect more high-resolution images and images that do not contain anime icons.\n",
    "\n",
    "Balancing the dataset was a key challenge in this project. Ensuring that there is an equal number of images for both classes (mask and no mask) is crucial for avoiding biased results. The implementation of image augmentation techniques was also beneficial in increasing the diversity of the training data and preventing overfitting.\n",
    "\n",
    "For future work, there are several potential directions for improving the model's performance. These include experimenting with different architectures, tuning the hyperparameters, and using more advanced techniques for handling imbalanced data.\n",
    "\n",
    "In conclusion, this project has demonstrated the potential of deep learning for mask detection, a critical task in the context of the ongoing COVID-19 pandemic. It has also highlighted the importance of careful data preparation and model evaluation in achieving reliable and interpretable results. The insights gained from this project, particularly regarding the types of images that the model struggles with, will be valuable for further improving the model and ultimately enhancing its effectiveness in real-world applications."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "CS767.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
