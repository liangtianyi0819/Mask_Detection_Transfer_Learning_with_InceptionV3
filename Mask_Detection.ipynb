{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jB-kW9JnHYdK"
   },
   "source": [
    "# Mask Detection using Transfer Learning based on InceptionV3 Neural Network\n",
    "Author: [Tianyi Liang](https://www.linkedin.com/in/tianyi-liang-at-bu/)\n",
    "\n",
    "## Introduction\n",
    "This project aims to detect whether a person is wearing a mask or not using a Convolutional Neural Network (CNN) model. The model is built using transfer learning based on the InceptionV3 architecture. The dataset used for this project is publicly available on Kaggle.\n",
    "\n",
    "This project is divided into several sections:\n",
    "\n",
    "1. [Import Necessary Packages](#import-packages)\n",
    "2. [Download the Dataset](#download-dataset)\n",
    "3. [Read the Data into Memory](#read-data)\n",
    "4. [Perform Data Visualization](#data-visualization)\n",
    "5. [Normalize the Data and Format it into the Required Shape](#normalize-data)\n",
    "6. [Check the Balance of the Data](#check-balance)\n",
    "7. [Implement Image Augmentation to Prevent Overfitting](#image-augmentation)\n",
    "8. [Build the Network using InceptionV3 and a Custom Classifier](#build-network)\n",
    "9. [Train the Model on the Augmented Data](#train-model)\n",
    "10. [Evaluate the Model and Analyze Wrong Cases](#evaluate-model)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"import-packages\"></a>\n",
    "## Import Necessary Packages\n",
    "In this stage, we import all the necessary packages required for the project. These include TensorFlow, Keras, OpenCV, opendatasets, Numpy, Pandas, Seaborn, and Matplotlib.\n",
    "\n",
    "### Requirements:\n",
    "- Python 3.7\n",
    "- TensorFlow\n",
    "- Keras\n",
    "- OpenCV\n",
    "- opendatasets\n",
    "- Numpy\n",
    "- Pandas\n",
    "- Seaborn\n",
    "- Matplotlib\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o8e0yTJktvxY",
    "outputId": "033dd8b0-cc08-4eb3-f6e0-de01b3cc7064",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "##Import necessary packages\n",
    "!pip install opendatasets\n",
    "!pip install opencv-python\n",
    "!pip install opencv-contrib-python\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import opendatasets as od\n",
    "\n",
    "from cv2 import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation, Input, Add, \\\n",
    "                   BatchNormalization, Flatten, Conv2D, \\\n",
    "                   AveragePooling2D, MaxPooling2D, ZeroPadding2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTh3lMfEH6vu"
   },
   "source": [
    "<a id=\"download-dataset\"></a>\n",
    "## Download the Dataset\n",
    "We download the dataset from Kaggle using the opendatasets package. The dataset contains images of people with and without masks.\n",
    "##### (Link to the dataset: [Face Mask 12k Images Dataset by ASHISH JANGRA](https://www.kaggle.com/datasets/ashishjangra27/face-mask-12k-images-dataset))\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BEQhzQLtvtQ",
    "outputId": "131fd8d4-e600-4ef8-c8c3-d2d7bf06dc33"
   },
   "outputs": [],
   "source": [
    "od.download(\"https://www.kaggle.com/datasets/ashishjangra27/face-mask-12k-images-dataset\")\n",
    "root_path = \"face-mask-12k-images-dataset/Face Mask Dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXd3wTngII3l"
   },
   "source": [
    "<a id=\"read-data\"></a>\n",
    "## Read the Data into Memory\n",
    "In this stage, we read the data into memory. We load the images and their corresponding labels (mask or no mask) into a Pandas DataFrame.\n",
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fd4cN8t5vTgW",
    "outputId": "6ace4040-d47f-4bff-fc7b-e1b92f335d01"
   },
   "outputs": [],
   "source": [
    "dataset = {\"path\": [], \"classification\": [], \"set\": [], \"value\": []}\n",
    "\n",
    "# Train or test folder\n",
    "for train_test in os.listdir(root_path):\n",
    "\n",
    "    # Mask or WithoutMask folder\n",
    "    for true_false in os.listdir(root_path+\"/\"+train_test):\n",
    "\n",
    "        # Each image inside\n",
    "        for image in glob.glob(root_path + \n",
    "                     train_test + \"/\" + \n",
    "                     true_false + \"/\" + \n",
    "                     \"*.png\"):\n",
    "\n",
    "            this_path = str(root_path + \n",
    "                     train_test + \"/\" + \n",
    "                     true_false + \"/\" + \n",
    "                     image)\n",
    "            img = cv2.imread(image, 3)\n",
    "            img = np.asarray(cv2.resize(img, \n",
    "                    dsize=(224, 224)))\n",
    "            img = cv2.merge(cv2.split(img)[::-1])\n",
    "            dataset[\"path\"].append(image)\n",
    "            if true_false == \"WithMask\":\n",
    "                dataset[\"classification\"].append(np.uint8(1))\n",
    "            else:\n",
    "                dataset[\"classification\"].append(np.uint8(0))\n",
    "            dataset[\"set\"].append(train_test.lower())\n",
    "            dataset[\"value\"].append(img)\n",
    "\n",
    "df_dataset = pd.DataFrame(dataset)\n",
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_XICQkmISpz"
   },
   "source": [
    "<a id=\"data-visualization\"></a>\n",
    "## Perform Data Visualization\n",
    "We visualize the data to get a better understanding of it. We plot some sample images from the dataset and their corresponding labels.\n",
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "id": "E8AKiAzowMSR",
    "outputId": "3e2bf262-5002-4289-9e9b-07163b133ae4"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 15))\n",
    "np.random.seed(1)\n",
    "sample = np.random.choice(range(len(df_dataset)), size=25, replace=False)\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    img = df_dataset.loc[sample[i],\"value\"]\n",
    "    plt.imshow(img)\n",
    "    classification = 'WithMask' if df_dataset.loc[sample[i],\"classification\"] == 1 else \"WithoutMask\"\n",
    "    plt.title(classification, size = 15)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWrdB79eIjdK"
   },
   "source": [
    "<a id=\"normalize-data\"></a>\n",
    "## Normalize the Data and Format it into the Required Shape <a name=\"normalize-data\"></a>\n",
    "We normalize the pixel values of the images to be between 0 and 1. We also format the data into the shape required by the InceptionV3 model.\n",
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsPapFBq0NLV",
    "outputId": "37451fe2-0054-4fe2-c655-3b40c3bb0da3"
   },
   "outputs": [],
   "source": [
    "def set_seed():\n",
    "    InitSeed = 23\n",
    "    tf.random.set_seed(InitSeed)\n",
    "    np.random.seed(InitSeed)\n",
    "\n",
    "\n",
    "train_set = pd.DataFrame(df_dataset[df_dataset[\"set\"] == \"train\"]).loc[:, [\"value\", \"classification\"]]\n",
    "test_set = pd.DataFrame(df_dataset[df_dataset[\"set\"] == \"test\"]).loc[:, [\"value\", \"classification\"]]\n",
    "valid_set = pd.DataFrame(df_dataset[df_dataset[\"set\"] == \"validation\"]).loc[:, [\"value\", \"classification\"]]\n",
    "\n",
    "x_train = np.asarray(train_set[\"value\"].tolist()) / 255\n",
    "y_train = np.asarray(train_set[\"classification\"].tolist())\n",
    "x_test = np.asarray(test_set[\"value\"].tolist()) / 255\n",
    "y_test = np.asarray(test_set[\"classification\"].tolist())\n",
    "x_valid = np.asarray(valid_set[\"value\"].tolist()) / 255\n",
    "y_valid = np.asarray(valid_set[\"classification\"].tolist())\n",
    "\n",
    "del df_dataset, train_set, test_set, valid_set, img, dataset, this_path\n",
    "del glob, od, pd, cv2\n",
    "gc.collect()\n",
    "print(\"x_train dimension:\", x_train.shape, \"\\ny_train dimension:\", y_train.shape,\n",
    "   \"\\nx_test dimension:\", x_test.shape, \"\\ny_test dimension:\", y_test.shape,\n",
    "   \"\\nx_valid dimension:\", x_valid.shape, \"\\ny_valid dimension:\", y_valid.shape,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FW6xy_5wJYbJ"
   },
   "source": [
    "<a id=\"check-balance\"></a>\n",
    "## Check the Balance of the Data <a name=\"check-balance\"></a>\n",
    "We need to ensure that our dataset is balanced, i.e., there is an equal number of images for both classes (mask and no mask). An imbalanced dataset can lead to biased results, where the model might favor the class with more instances.\n",
    "\n",
    "### Data Balance Verification\n",
    "\n",
    "We calculate the number of instances for each class in the training, testing, and validation sets. The results are then visualized using a bar chart for a more intuitive understanding of the data distribution.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "-XyMKUCwDsop",
    "outputId": "a1253fae-9300-4fed-f9e9-12c71de54f91"
   },
   "outputs": [],
   "source": [
    "classes_distribution = {\"WithoutMask in Train\": np.sum(y_train == 0), \n",
    "              \"With in Train\": np.sum(y_train == 1),\n",
    "              \"WithoutMask in Test\": np.sum(y_test == 0),\n",
    "              \"With in Test\": np.sum(y_test == 1),\n",
    "              \"WithoutMask in Validation\": np.sum(y_valid == 0),\n",
    "              \"With in Validation\": np.sum(y_valid == 1)}\n",
    "plt.figure(figsize = (16, 9))\n",
    "color_A = (0.1, 0.4, 0.7)\n",
    "color_B = color_A[::-1]\n",
    "plt.bar(range(len(classes_distribution)), \n",
    "        list(classes_distribution.values()), \n",
    "        tick_label=list(classes_distribution.keys()),\n",
    "        color=[color_A, color_B])\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVs_k8YCJoZ2"
   },
   "source": [
    "<a id=\"image-augmentation\"></a>\n",
    "## Implement Image Augmentation to Prevent Overfitting\n",
    "To increase the diversity of the training data and prevent overfitting, we implement image augmentation techniques. These techniques include rotation, height shift, width shift, zoom, and horizontal flip.\n",
    "\n",
    "### Image Augmentation Setup\n",
    "\n",
    "We use the `ImageDataGenerator` function from Keras to create an image generator that can apply these augmentations to the training images. The parameters for the different augmentations are set as follows:\n",
    "\n",
    "- **Rotation**: Up to 30 degrees\n",
    "- **Height Shift**: Up to 10% of the image height\n",
    "- **Width Shift**: Up to 10% of the image width\n",
    "- **Zoom**: Up to 10%\n",
    "- **Horizontal Flip**: Enabled\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "sDZqB-RpkKQc",
    "outputId": "804f1a62-5559-49e4-bb90-819209782637"
   },
   "outputs": [],
   "source": [
    "set_seed()\n",
    "train_aug = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    height_shift_range=.1,\n",
    "    width_shift_range=.1,\n",
    "    zoom_range=.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "augment = train_aug.flow(x_train[0:1], batch_size=1)\n",
    "\n",
    "# Check if the augmentation works\n",
    "plt.figure(figsize = (20, 15))\n",
    "for i in range(1, 26):\n",
    "    plt.subplot(1 + 5 % i, 5, i)\n",
    "    tf.random.set_seed(1)\n",
    "    augment.reset()\n",
    "    plt.imshow(augment.next().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "del augment\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNx-l0f-J28i"
   },
   "source": [
    " <a id=\"build-network\"></a>\n",
    "## Build the Network using InceptionV3 and a Custom Classifier\n",
    "We build the network using the InceptionV3 model and a custom classifier. The model is based on the InceptionV3 architecture, a popular convolutional neural network (CNN) for image classification tasks.\n",
    "\n",
    "We build the network using the InceptionV3 model and a custom classifier. The model is based on the InceptionV3 architecture, a popular convolutional neural network (CNN) for image classification tasks.\n",
    "\n",
    "\n",
    "### Custom Classifier: `classifier_`\n",
    "\n",
    "This function defines a custom classifier that is added on top of the InceptionV3 base model. This classifier consists of several dense (fully connected) layers, each followed by batch normalization, activation, and dropout layers.\n",
    "\n",
    "- **Batch Normalization Layers**: These help to stabilize the learning process and reduce the generalization error.\n",
    "- **Dropout Layers**: These help to prevent overfitting by randomly setting a fraction of the input units to 0 at each update during training time.\n",
    "\n",
    "\n",
    "### Model Construction: `model_flow`\n",
    "\n",
    "This function constructs the overall model by first applying the InceptionV3 base model to the input, and then applying the custom classifier to the output of the base model.\n",
    "\n",
    "\n",
    "### Model Compilation: `input_output_compile`\n",
    "\n",
    "This function creates the final model by specifying the input and output, and compiles the model with the Stochastic Gradient Descent (SGD) optimizer, the sparse categorical cross-entropy loss function, and accuracy as the evaluation metric.\n",
    "\n",
    "\n",
    "### Learning Rate Scheduler: `lr_decay`\n",
    "\n",
    "This function defines a learning rate scheduler that decreases the learning rate as the training progresses, which can help to improve the convergence of the model.\n",
    "\n",
    "\n",
    "### Model Training: `fit_generator`\n",
    "\n",
    "The model is trained on the training data using the `fit_generator` method, with data augmentation applied to the training images to increase the diversity of the training data and help prevent overfitting. The learning rate scheduler is passed to the `fit_generator` method as a callback, so that the learning rate is updated at the end of each epoch.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gayA6Sqxrm0S"
   },
   "outputs": [],
   "source": [
    "def classifier_(input_):\n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed=767)\n",
    "    output_ = keras.layers.GlobalAveragePooling2D()(input_)\n",
    "    output_ = keras.layers.Flatten()(output_)\n",
    "    output_ = keras.layers.BatchNormalization()(output_)\n",
    "    output_prime = output_\n",
    "\n",
    "    output_ = keras.layers.Dense(2048, kernel_initializer=initializer)(output_)\n",
    "    output_ = keras.layers.BatchNormalization()(output_)\n",
    "    output_ = keras.layers.Activation('relu')(output_)\n",
    "    output_ = keras.layers.Dropout(0.55)(output_)\n",
    "\n",
    "    output_ = keras.layers.Dense(2048, kernel_initializer=initializer)(output_)\n",
    "    output_ = keras.layers.BatchNormalization()(output_)\n",
    "    output_ = keras.layers.Activation('relu')(output_)\n",
    "    output_ = keras.layers.Dropout(0.55)(output_)\n",
    "\n",
    "    output_ = keras.layers.Dense(1024, kernel_initializer=initializer)(output_)\n",
    "    output_ = keras.layers.BatchNormalization()(output_)\n",
    "    output_ = keras.layers.Activation('relu')(output_)\n",
    "    output_ = keras.layers.Dropout(0.55)(output_)\n",
    "\n",
    "    output_ = keras.layers.Concatenate()([output_, output_prime])\n",
    "\n",
    "    output_ = keras.layers.Dense(512, activation='relu', kernel_initializer=initializer)(output_)\n",
    "    output_ = keras.layers.Dense(2, activation='softmax')((output_))\n",
    "    return output_\n",
    "\n",
    "\n",
    "def model_flow(input_):\n",
    "    output_ = tf.keras.applications.InceptionV3(input_shape=(224, 224, 3),\n",
    "                               include_top=False,\n",
    "                               weights=None)(input_)\n",
    "\n",
    "    # output_ a fc1000 classification at this point\n",
    "    # Add the self-designed classifier to produce binary result\n",
    "    output_ = classifier_(output_)\n",
    "    return output_\n",
    "\n",
    "\n",
    "def input_output_compile():\n",
    "\n",
    "    # Shape of the training set\n",
    "    input_ = keras.layers.Input(shape=(224, 224, 3))\n",
    "    output_ = model_flow(input_)\n",
    "    clf = keras.Model(inputs=input_, outputs=output_)\n",
    "\n",
    "    clf.compile(optimizer='SGD', loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return clf\n",
    "\n",
    "\n",
    "# Define learning rate scheduler\n",
    "def lr_decay(epoch, lr):\n",
    "    if epoch == 0:\n",
    "\n",
    "        # Do not print evaluation at the beginning of the training\n",
    "\n",
    "        return lr * 1 / (1 + 0.05 * epoch)\n",
    "    if epoch % 5 == 0:\n",
    "        \n",
    "        # Print test accuracy every 5 epochs\n",
    "        print('Test set accuracy: ' +\n",
    "              str(np.round(model.evaluate(x_test, y_test)[1] * 100, 2)) + '%')\n",
    "    return lr * 1 / (1 + 0.05 * epoch)\n",
    "\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Visualize the neural network structure\n",
    "model = input_output_compile()\n",
    "tf.keras.utils.plot_model(model, show_shapes=True,\n",
    "              show_dtype=False,\n",
    "              show_layer_names=False,\n",
    "              show_layer_activations=True)\n",
    "\n",
    "## Start the training on augmentation generater\n",
    "set_seed()\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_decay)\n",
    "hist = model.fit_generator(train_aug.flow(x_train, y_train, batch_size=24),\n",
    "                    epochs=8,\n",
    "                    # steps_per_epoch=X_train.shape[0]//batch_size,\n",
    "                    validation_data=(x_valid, y_valid),\n",
    "                    # validation_steps=X_valid.shape[0]//batch_size\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ctvovc-MWlZ"
   },
   "source": [
    "## Visualize the change of accuracy and loss during the training\n",
    "In the following code block, we are visualizing the change in accuracy and loss during the training process. The accuracy and loss for both the training and validation sets are extracted from the history object returned by the model's fit method.\n",
    "\n",
    "The accuracy and loss values are plotted against the number of epochs to show how the model's performance improved over time during training. The blue line represents the training data, while the orange line represents the validation data.\n",
    "\n",
    "The first plot shows the accuracy of the model over time. Ideally, we want to see the accuracy increasing over time, indicating that the model is learning from the training data.\n",
    "\n",
    "The second plot shows the loss of the model over time. Ideally, we want to see the loss decreasing over time, indicating that the model is getting better at predicting the correct classes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kpGImxT4s5AY",
    "outputId": "6fd04bdf-6c12-441a-9581-d237cbbd59c6"
   },
   "outputs": [],
   "source": [
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.figure(figsize = (16, 8))\n",
    "plt.plot(epochs, acc, label='Training acc')\n",
    "plt.plot(epochs, val_acc, label='Validation acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.figure(figsize = (13, 8))\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8pl90zqMlB9"
   },
   "source": [
    "## Evaluate the result and analyze wrong cases\n",
    "> *    Plot wrong-predicted images\n",
    "> *    Calculate TN, FN, TP, FP\n",
    "> *    Calculate Reall, Precision, Specificity Rates\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pZ1HvP_-Xz_",
    "outputId": "118be517-5f82-4c89-a03f-8dc252944055"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "id": "ID6UhnWm-sbg",
    "outputId": "0e3ce497-3d52-49c8-a923-75d5014d897f"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "correct_ = np.equal(np.argmax(y_pred, 1), y_test)\n",
    "x_wrong = x_test[np.logical_not(correct_)]\n",
    "from re import X\n",
    "# Check if the augmentation works\n",
    "plt.figure(figsize = (20, 15))\n",
    "for i in range(1, len(x_wrong)-1):\n",
    "    plt.subplot(1 + 5 % i, 5, i)\n",
    "    plt.imshow(x_wrong[i].squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWcAaYBmQQ_r",
    "outputId": "9745bbc5-d4a2-4f79-e40e-bbedb7976596"
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred, 1)\n",
    "TP = np.sum(np.logical_and(y_pred == 0, y_test == 0))\n",
    "FP = np.sum(np.logical_and(y_pred == 0, y_test == 1))\n",
    "TN = np.sum(np.logical_and(y_pred == 1, y_test == 1))\n",
    "FN = np.sum(np.logical_and(y_pred == 1, y_test == 0))\n",
    "print('TP:', TP, '\\nFP:', FP, '\\nTN:', TN, '\\nFN:', FN)\n",
    "print(\"\\nFP: predict as WithoutMask but actually WithMask\",\n",
    "   \"\\nFN: predict as WithMask but actually WithoutMask\")\n",
    "\n",
    "# IMPORTANT when false ALARM is unacceptable\n",
    "precision = str(np.round((TP/(TP+FP))*100, 2)) + \"%\"\n",
    "\n",
    "# IMPORTANT when missing ALARM is unacceptable, \n",
    "# rather have some fake ALARM\n",
    "recall = str(np.round((TP/(TP+FN))*100, 2)) + \"%\"\n",
    "\n",
    "# IMPORTANT when false ALARM is unacceptable\n",
    "specificity = str(np.round((TN/(TN+FP))*100, 2)) + \"%\"\n",
    "\n",
    "print(\"\\nPrecision:\", precision,\"\\nRecall:\", recall,\n",
    "    \"\\nSpecificity:\", specificity)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "CS767.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
